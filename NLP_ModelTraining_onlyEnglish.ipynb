{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Model Training\n",
    "\n",
    "This notebook contains the model training for the filtered data, where only songs in English are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spark\n",
    "\n",
    "First, we obviously need Spark again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/spark/\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import collections\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"NLP2\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .config(\"spark.sql.random.seed\", \"1234\") \\\n",
    "   .getOrCreate()\n",
    "      \n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read file, drop some columns and recast some variable types\n",
    "\n",
    "We load the data and as we can see, all columns are strings. We delete the first column, as it is just another id variable and we don't need 2 of them. Then we change the datatype of id and label to integers (needed for model training afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+-----+\n",
      "|_c0|   id|                text|label|\n",
      "+---+-----+--------------------+-----+\n",
      "|  0|44054|let lover marry f...|  1.0|\n",
      "+---+-----+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.utils import AnalysisException \n",
    "\n",
    "try: \n",
    "    data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"escapeQuotes\", \"false\").load(\"../Final Preprocessing/NLP_processed_onlyEnglish.csv\")\n",
    "    data.show(1)\n",
    "except AnalysisException: \n",
    "    print(\"Please check the Filename and Filepath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  1.0| 8752|\n",
      "|  0.0|26598|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " data.select('label').groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"_c0\")\n",
    "data = data.withColumn(\"id\", data[\"id\"].cast(\"integer\"))\n",
    "data = data.withColumn(\"label\", data[\"label\"].cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating an 50% Billboard-Songs and 50% not Billboard-Songs Dataset \n",
    "\n",
    "First we again drop some NAs that we introduced at some unknown point again (theory for that at the top). Now we split the data so that we have a dataset that contains 50% Billboard and 50% not Billboard songs. The seed for this was set at the beginning of the spark session and is the same for all the models. We did this split since we feared that the model might overperform when the amount of songs in the billboard was proportionally too small compared to the number of songs not in the billboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = data.groupBy(\"label\").count().collect()\n",
    "\n",
    "min_count = min(row['count'] for row in label_counts)\n",
    "\n",
    "# Create balanced DataFrame by sampling\n",
    "balanced_df = None\n",
    "\n",
    "for row in label_counts:\n",
    "    label = row['label']\n",
    "    count = row['count']\n",
    "    fraction = min_count / count  # Calculate the fraction of the data to sample\n",
    "    \n",
    "    # Sample the data\n",
    "    sampled_df = data.filter(col(\"label\") == label).sample(False, fraction, seed=1)\n",
    "    \n",
    "    # Append sampled data to the balanced DataFrame\n",
    "    if balanced_df is None:\n",
    "        balanced_df = sampled_df.limit(min_count)  # Use limit to ensure exact number of instances\n",
    "    else:\n",
    "        balanced_df = balanced_df.union(sampled_df.limit(min_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.drop(\"_c0\")\n",
    "balanced_df = balanced_df.withColumn(\"id\", balanced_df[\"id\"].cast(\"string\"))\n",
    "balanced_df = balanced_df.withColumn(\"label\", balanced_df[\"label\"].cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 8736|\n",
      "|    1| 8752|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "balanced_df.select('label').groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.na.drop()\n",
    "balanced_training_df_0, balanced_test_df_0 = balanced_df.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----+\n",
      "|   id|                text|label|\n",
      "+-----+--------------------+-----+\n",
      "|    1|baby fight comin ...|    1|\n",
      "|10001|summer rain tap w...|    1|\n",
      "|10002|plate pile high d...|    1|\n",
      "+-----+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "balanced_training_df_0.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initiate pipeline\n",
    "\n",
    "We initiate the pipeline: import necessary libraries and set up our function that we'll use later. These include the tokenizer, HashingTF, a function to calculate idf and a Naive Bayes Classifier. What all of these roughly do is explained in the steps 5-7 below. The Naive Bayes classifier doesn't have a seperate section, it's essentially a way of classifying something using probabilities. We use it to predict whether a song was in the charts or not (predicts the \"label\" column).\n",
    "\n",
    "IMPORTANT: Step 4 sets up our functions. Steps 5-7 do not need to be executed, but they serve as a visual help to see what is happening. For the model training, the functions specified in step 4 are called during the crossvalidation (step 9) as part of the pipeline created in step 8. The tokenizer takes a \"text\" column as input from the training data, HashingTF takes the tokenizer's output column as input and IDF takes the output of HashingTF as input. So each stage uses the output of the stage before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "\n",
    "# Term Frequency (TF)\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "#Inverse Document Frequency (IDF)\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "\n",
    "# Naive Bayes Classifiers.\n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tokenize\n",
    "\n",
    "We tokenize the input, meaning we convert all words to lowercase and then split them by whitespace. This gives us the words of the text and puts them in another column so that we can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_balanced = tokenizer.transform(balanced_training_df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----+--------------------+\n",
      "|   id|                text|label|               words|\n",
      "+-----+--------------------+-----+--------------------+\n",
      "|    1|baby fight comin ...|    1|[baby, fight, com...|\n",
      "|10001|summer rain tap w...|    1|[summer, rain, ta...|\n",
      "+-----+--------------------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_balanced.show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hash Term Frequency\n",
    "\n",
    "Term frequency is a metric of how often a word occurs in a document compared to the total number of words in that document (each row is a document in our case). The function \"HashingTF\" takes sets of terms (in our case a bag of words) and converts those sets into fixed-length feature vectors. The algorithm combines Term Frequency (TF) counts with the hashing trick for dimensionality reduction. We create these feature vectors because they are needed for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|words                                                                                                                                                                                                                                                         |features                                                                                                                                                                                                                                                                      |label|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[baby, fight, comin, baby, know, tree, life, reason, grows, ask, question, darling, know, clear, love, don, ask, ask, lord, love, paint, sky, clear, blue, way, way, way, nature, plan, meant, meant, mean, stay, way, way, way, nature, plan, don, ask, love]|(262144,[30084,51471,56808,59225,73249,90723,103048,131709,136433,140931,146542,157120,170555,172517,175464,176996,186480,192000,193711,200147,204931,206250,224635,232427],[1.0,6.0,1.0,2.0,1.0,4.0,1.0,1.0,1.0,2.0,1.0,1.0,2.0,1.0,2.0,2.0,3.0,1.0,1.0,1.0,1.0,1.0,2.0,2.0])|1    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashed_balanced = hashingTF.transform(tokenized_balanced)\n",
    "hashed_balanced.select(\"words\",\"features\",\"label\").show(n=1,truncate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Calculate IDF\n",
    "\n",
    "Now we calculate inverse document frequency or IDF in short. The IDF of a term reflects the proportion of documents (aka rows aka songs) that contain the term in the whole file. Terms that appear in only a small number of documents are perceived as more important than words that are commonly used. This is gonna help the model, as it needs to give some type of numerical value to the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced = idf.fit(hashed_balanced)\n",
    "tfidf_balanced = model_balanced.transform(hashed_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |text                                                                                                                                                                                                                |label|words                                                                                                                                                                                                                                                         |features                                                                                                                                                                                                                                                                      |idf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |baby fight comin baby know tree life reason grows ask question darling know clear love don ask ask lord love paint sky clear blue way way way nature plan meant meant mean stay way way way nature plan don ask love|1    |[baby, fight, comin, baby, know, tree, life, reason, grows, ask, question, darling, know, clear, love, don, ask, ask, lord, love, paint, sky, clear, blue, way, way, way, nature, plan, meant, meant, mean, stay, way, way, way, nature, plan, don, ask, love]|(262144,[30084,51471,56808,59225,73249,90723,103048,131709,136433,140931,146542,157120,170555,172517,175464,176996,186480,192000,193711,200147,204931,206250,224635,232427],[1.0,6.0,1.0,2.0,1.0,4.0,1.0,1.0,1.0,2.0,1.0,1.0,2.0,1.0,2.0,2.0,3.0,1.0,1.0,1.0,1.0,1.0,2.0,2.0])|(262144,[30084,51471,56808,59225,73249,90723,103048,131709,136433,140931,146542,157120,170555,172517,175464,176996,186480,192000,193711,200147,204931,206250,224635,232427],[3.7975624696288897,10.026457776245,4.180979440515292,9.748253242150474,2.7269390908630124,13.172506575846679,3.272193434295204,3.0411713954089143,5.936037542892919,1.9208455720845852,3.322397026261783,3.6173663121472486,8.315767451441284,1.9941933713229956,4.585555218161249,3.635319562453323,3.6678573684907283,4.243650547478067,4.095917001971443,3.1140153627979634,4.447089027712944,4.710673548585665,11.98321478809546,7.995758741283846])|\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_balanced.show(n=1,truncate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create pipeline and parameter grid\n",
    "\n",
    "We create a simple pipeline, which consists of a sequence of stages, each stage is either an estimator or a transformer. We'll call the pipeline in the next step and then all the stages will be executed in their specified order, which helps us automate the process of finding good parameters. If an estimator is called, a model will be fit on the input. Then the model (which is a transformer) is used to transform the data as the input to the next stage. If a transformer is called, the current input will be transformed to produce the input for the next stage. So overall we create a bunch of models and transform our data a few times when calling our pipeline (in the ways specified in the steps above). The stages are tokenizing, finding term frequency, calculating IDF and calling the Naive Bayes classifier, as mentioned in the steps above. \n",
    "\n",
    "The paramGrid sets the parameters specified in the grid to specific values. This allows us to test for the optimal value of a parameter during the next step. Concretely, we are testing several values for \"numFeatures\" (which is a parameter of HashingTF, see step 6) to find the value that gives us the best performance during model training and evaluation. The nb.smoothing parameter adds a small probability value to whenever the Naive Bayes classifier would give something probability zero. We do this because zero probabilities can lead to errors in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 500, 1000]) \\\n",
    "    .addGrid(nb.smoothing, [0.0, 1.0]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Run cross validation\n",
    "\n",
    "With our pipeline of functions to call and our parameter grid to test different values ready, we start the cross validation. K-fold cross validation splits the dataset into K non-overlapping randomly partitioned folds which are used as separate training and test datasets. So with e.g. 10 folds, 9 of the folds are used to train the model and the remaining fold is used for testing. We do this so that each fold is used for testing once. By increasing the number of folds, we reduce the likelihood of missing out on important data that might only be present in the test split and not the training split when using e.g. 2 folds. However, the runtime needed also increases with more folds. \n",
    "\n",
    "We tested different numbers of folds and found that the quality of the predictions did not increase by much, so we chose to stuck with two folds for improved runtime. After creating the cross validator, we train our final models, using the training split. We do this and the following steps twice, once for the full data and once for the balanced data (see step 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation \n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=2)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel_balanced = cv.fit(balanced_training_df_0)\n",
    "bestModel = cvModel_balanced.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create predictions\n",
    "\n",
    "We use our final models created in the last step and apply them on the test split. Now our predictions have been made and we can evaluate them. For that and to showcase the result, we once again select only the variables of interest (text, label and prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_balanced = bestModel.transform(balanced_test_df_0)\n",
    "\n",
    "# Projects a set of expressions \n",
    "prediction_df_balanced = result_balanced.select(\"text\", \"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                               |label|prediction|\n",
      "+-------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "|lord old tune fiddle guitar take rhinestone suit new shiny car way year need change somebody tell come son get make|1    |1.0       |\n",
      "|talk sleep anything believe word day anything heard talk night right call though hear name speak name              |1    |1.0       |\n",
      "+-------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_df_balanced.show(n=2,truncate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Result\n",
    "\n",
    "In this step we only compare the results. We focus on AUC (section c), as we are equally interested in false negatives and false positives and overall just want to know how many labels we predicted correctly. We are also interested in the actual proportions of chart songs and non-chart songs (section a) and the proportion of positive/negative prediction (section b). If the proportions in a) and b) vary greatly, this would indicate that the model may be overly optimistic or pessimistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells show how many songs of the test data were within the charts:\n",
    "\n",
    "Balanced data: roughly 50% --> something went wrong with creation of the balanced data as it's not exact, but not too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1764|\n",
      "|    1| 1720|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_df_balanced.select('label').groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the model predicts:\n",
    "\n",
    "Balanced data: same here with roughly 48% being rather close to the actual 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0| 1752|\n",
      "|       1.0| 1732|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_df_balanced.select('prediction').groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only English model is far closer to the actual proportions than the model trained on all songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set AUC (ROC) = 0.4211017837367505\n",
      "Test set AUC (PR) = 0.43024811479057956\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Transform the test data using the best model\n",
    "predictions = bestModel.transform(balanced_test_df_0)\n",
    "\n",
    "# Initialize the evaluator \n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label')\n",
    "\n",
    "# Evaluate the model\n",
    "areaUnderROC = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})\n",
    "areaUnderPR = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderPR\"})\n",
    "\n",
    "print(\"Test set AUC (ROC) = \" + str(areaUnderROC))\n",
    "print(\"Test set AUC (PR) = \" + str(areaUnderPR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  625|\n",
      "|    0|       1.0|  637|\n",
      "|    0|       0.0| 1127|\n",
      "|    1|       1.0| 1095|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix = predictions.groupBy(\"label\", \"prediction\").count()\n",
    "confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6377726750861079\n",
      "Precision: 0.6322170900692841\n",
      "Recall: 0.6366279069767442\n",
      "F1 Score: 0.6344148319814601\n"
     ]
    }
   ],
   "source": [
    "# Assigning the needed values from the confusion matrix - https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec\n",
    "\n",
    "# True Positive\n",
    "TP = confusion_matrix.filter((col(\"label\") == 1) & (col(\"prediction\") == 1)).collect()[0][\"count\"]\n",
    "\n",
    "# False Positive\n",
    "FP = confusion_matrix.filter((col(\"label\") == 0) & (col(\"prediction\") == 1)).collect()[0][\"count\"]\n",
    "\n",
    "# True Negative\n",
    "TN = confusion_matrix.filter((col(\"label\") == 0) & (col(\"prediction\") == 0)).collect()[0][\"count\"]\n",
    "\n",
    "# False Negative\n",
    "FN = confusion_matrix.filter((col(\"label\") == 1) & (col(\"prediction\") == 0)).collect()[0][\"count\"]\n",
    "\n",
    "\n",
    "# Calculating the metrics\n",
    "Accuracy = (TP + TN)/(TP + TN + FP + FN) \n",
    "Precision = TP/(TP + FP) \n",
    "Recall = TP/(TP + FN) \n",
    "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {Accuracy}\")\n",
    "print(f\"Precision: {Precision}\")\n",
    "print(f\"Recall: {Recall}\")\n",
    "print(f\"F1 Score: {F1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Discussion of results of all NLP models\n",
    "\n",
    "- The accuracy of the unfiltered balanced data is around: 0.71\n",
    "- The accuracy of the only English balanced data is around: 0.63\n",
    "\n",
    "This is roughly what we expected. When training with unfiltered data, the model performs better because it can plainly assign all non-English songs a prediction of \"0\" and with high likelihood, this is correct as usually only English songs are in the billboard hot 100. When the data consists of only English songs, this trick doesn't work anymore.\n",
    "Arguably, it may also have something to do with the size of the dataset, as the unfiltered data is obviously bigger. However, I do not think this plays a role here. \n",
    "\n",
    "Our claim is supported by the fact that when looking at the unfiltered data prediction, the model tends to either be very optimistic or pessimistic. For the full data prediction, it classifies almost all songs as non-chart songs, and for the balanced data prediction, it classifies most songs as chart songs. \n",
    "Contrary to that, the model trained on only English songs predicts the values in a ratio that is much closer to the actual ratio of \"chart songs\" and \"non-chart songs\" in the test split. (Compare the first 4 cells of the \"result\" section in both notebooks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
